{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:19:45.391899Z",
     "start_time": "2019-10-19T19:19:45.275619Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time as tm\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:19:46.656752Z",
     "start_time": "2019-10-19T19:19:46.652747Z"
    }
   },
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"VID_PATH\", help=\"Path to the video to be summarized\")\n",
    "# parser.add_argument(\"--INTERVAL_BW_DIVISIONS\", help=\"Interval between divisions to split the moving objects - more of this => longer video => less overlapping\")\n",
    "# args = parser.parse_args()\n",
    "VID_PATH = 'video3.webm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:19:47.592179Z",
     "start_time": "2019-10-19T19:19:47.588196Z"
    }
   },
   "outputs": [],
   "source": [
    "CONTINUITY_THRESHOLD = 10 #For cutting out boxes\n",
    "\n",
    "MIN_SECONDS = 2 # (seconds) Minimum duration of a moving object\n",
    "INTERVAL_BW_DIVISIONS = 10 # (seconds) For distributing moving objects over a duration to reduce overlapping.\n",
    "GAP_BW_DIVISIONS = 1.5 #(seconds)\n",
    "\n",
    "# if args.INTERVAL_BW_DIVISIONS:\n",
    "#     INTERVAL_BW_DIVISIONS = args.INTERVAL_BW_DIVISIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting boxes using BGSubtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:28:31.635010Z",
     "start_time": "2019-10-19T19:19:48.958774Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Will give boxes for each frame and simultaneously extract background\"\"\"\n",
    "\n",
    "cap  = cv2.VideoCapture(VID_PATH)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "ret, frame = cap.read()\n",
    "all_conts = []\n",
    "\n",
    "avg2 = np.float32(frame) #BG-Ext\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    #Background extraction\n",
    "    try:\n",
    "        cv2.accumulateWeighted(frame, avg2, 0.01)\n",
    "    except:\n",
    "        break\n",
    "    #if ret is true than no error with cap.isOpened\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        #apply background substraction\n",
    "        fgmask = fgbg.apply(frame)  \n",
    "        \n",
    "        #apply contours on foreground\n",
    "        (contours, hierarchy) = cv2.findContours(fgmask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        contours = np.array([np.array(cv2.boundingRect(c)) for c in contours if cv2.contourArea(c) >= 500])\n",
    "        all_conts.append(contours)\n",
    "        for c in contours:\n",
    "            \n",
    "            #get bounding box from countour\n",
    "            (x, y, w, h) = c\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "#         cv2.imshow('rgb', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "background = cv2.convertScaleAbs(avg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:28:31.646976Z",
     "start_time": "2019-10-19T19:28:31.638977Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_centres(p1):\n",
    "    return np.transpose(np.array([p1[:,0] + p1[:,2]/2, p1[:,1] + p1[:,3]/2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:31:26.097783Z",
     "start_time": "2019-10-19T19:31:26.089806Z"
    }
   },
   "outputs": [],
   "source": [
    "def distance(p1, p2):\n",
    "    p1 = np.expand_dims(p1, 0)\n",
    "    if p2.ndim==1:\n",
    "        p2 = np.expand_dims(p2, 0)\n",
    "        \n",
    "    c1 = get_centres(p1)\n",
    "    c2 = get_centres(p2)\n",
    "    return np.linalg.norm(c1 - c2, axis=1)\n",
    "\n",
    "def get_nearest(p1, points):\n",
    "    \"\"\"returns index of the point in *points* that is closest to p1\"\"\"\n",
    "    return np.argmin(distance(p1, points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:31:27.682098Z",
     "start_time": "2019-10-19T19:31:27.674049Z"
    }
   },
   "outputs": [],
   "source": [
    "class box:\n",
    "    def __init__(self, coords, time):\n",
    "        self.coords = coords #coordinates\n",
    "        self.time   = time #nth frame/time\n",
    "        \n",
    "class moving_obj:\n",
    "    def __init__(self, starting_box):\n",
    "        self.boxes = [starting_box]\n",
    "    \n",
    "    def add_box(self, box):\n",
    "        self.boxes.append(box)\n",
    "    \n",
    "    def last_coords(self):\n",
    "        return self.boxes[-1].coords\n",
    "    \n",
    "    def age(self, curr_time):\n",
    "        last_time = self.boxes[-1].time\n",
    "        return curr_time - last_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:45:34.786499Z",
     "start_time": "2019-10-19T16:45:34.269648Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Will associate boxes into objects\"\"\"\n",
    "#old - boxes in the previous frame\n",
    "#new - boxes in the current frame\n",
    "\n",
    "\n",
    "moving_objs = []\n",
    "\n",
    "for curr_time, new_boxes in enumerate(all_conts): #iterating over frames\n",
    "    if len(new_boxes) != 0: #if not empty\n",
    "        new_assocs = [None]*len(new_boxes) #all new boxes initially are not associated with any moving_objs\n",
    "        obj_coords = np.array([obj.last_coords() for obj in moving_objs if obj.age(curr_time)<CONTINUITY_THRESHOLD])\n",
    "        unexp_idx = -1 #index of unexpired obj in moving_objs\n",
    "        for obj_idx, obj in enumerate(moving_objs):\n",
    "            if obj.age(curr_time) < CONTINUITY_THRESHOLD: #checking only unexpired objects\n",
    "                unexp_idx += 1\n",
    "                nearest_new = get_nearest(obj.last_coords(), new_boxes) #nearest box to obj\n",
    "                nearest_obj = get_nearest(new_boxes[nearest_new], obj_coords) #nearest obj to box\n",
    "\n",
    "                if nearest_obj==unexp_idx: #both closest to each-other\n",
    "                    #associate\n",
    "                    new_assocs[nearest_new] = obj_idx\n",
    "    \n",
    "    \n",
    "    for new_idx, new_coords in enumerate(new_boxes):\n",
    "        new_assoc = new_assocs[new_idx]\n",
    "        new_box = box(new_coords, curr_time)\n",
    "\n",
    "        if new_assoc is not None: \n",
    "            #associate new box to moving_obj\n",
    "            moving_objs[new_assoc].add_box(new_box)\n",
    "        else: \n",
    "            #add a fresh, new moving_obj to moving_objs\n",
    "            new_moving_obj = moving_obj(new_box)\n",
    "            moving_objs.append(new_moving_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:45:34.795924Z",
     "start_time": "2019-10-19T16:45:34.789026Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removing objects that occur for a very small duration\n",
    "\n",
    "MIN_FRAMES = MIN_SECONDS*fps\n",
    "\n",
    "moving_objs = [obj for obj in moving_objs if (obj.boxes[-1].time-obj.boxes[0].time)>MIN_FRAMES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlaying moving objects on background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:45:34.915147Z",
     "start_time": "2019-10-19T16:45:34.797614Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut(image, coords):\n",
    "    (x, y, w, h) = coords\n",
    "    return image[y:y+h,x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:45:35.001619Z",
     "start_time": "2019-10-19T16:45:34.924887Z"
    }
   },
   "outputs": [],
   "source": [
    "def overlay(frame, image, coords):\n",
    "    (x, y, w, h) = coords\n",
    "    frame[y:y+h,x:x+w] = cut(image, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:45:35.075846Z",
     "start_time": "2019-10-19T16:45:35.003693Z"
    }
   },
   "outputs": [],
   "source": [
    "def sec2HMS(seconds):\n",
    "    return tm.strftime('%M:%S', tm.gmtime(seconds))\n",
    "\n",
    "def frame2HMS(n_frame, fps):\n",
    "    return sec2HMS(float(n_frame)/float(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:45:49.206593Z",
     "start_time": "2019-10-19T16:45:35.081103Z"
    }
   },
   "outputs": [],
   "source": [
    "max_orig_len = max(obj.boxes[-1].time for obj in moving_objs)\n",
    "max_duration = max((obj.boxes[-1].time - obj.boxes[0].time) for obj in moving_objs)\n",
    "#max_duration of a moving_obj. This is taken as the duration of the final summary\n",
    "start_times = [obj.boxes[0].time for obj in moving_objs]\n",
    "\n",
    "N_DIVISIONS = int(max_orig_len/(INTERVAL_BW_DIVISIONS))\n",
    "\n",
    "final_video  = [background.copy() for _ in range(max_duration+int(N_DIVISIONS*GAP_BW_DIVISIONS)+10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:46:00.213499Z",
     "start_time": "2019-10-19T16:45:50.267806Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Crop moving objects from main video and overlay them on the background\"\"\"\n",
    "cap  = cv2.VideoCapture(VID_PATH)\n",
    "# fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "ret, frame = cap.read() #original video\n",
    "# all_conts = []\n",
    "\n",
    "all_texts = []\n",
    "\n",
    "vid_time = -1\n",
    "while ret:\n",
    "    vid_time += 1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        for obj_idx, mving_obj in enumerate(moving_objs):\n",
    "            if mving_obj.boxes: #non-empty\n",
    "                first_box = mving_obj.boxes[0]\n",
    "                \n",
    "                if(first_box.time == vid_time):\n",
    "                    final_time = first_box.time - start_times[obj_idx] + int(int(start_times[obj_idx]/int(INTERVAL_BW_DIVISIONS*fps))*GAP_BW_DIVISIONS*fps)\n",
    "                    \n",
    "                    overlay(final_video[final_time-1], frame, first_box.coords)\n",
    "                    (x, y, w, h) = first_box.coords\n",
    "                    \n",
    "                    #TODO: DESIGN\n",
    "#                     all_texts.append((final_time-1, frame2HMS(first_box.time, fps), (x, y-10))) #Above\n",
    "                    all_texts.append((final_time-1, frame2HMS(first_box.time, fps), (x+int(w/2), y+int(h/2)))) #Centre\n",
    "    \n",
    "                    del(mving_obj.boxes[0])\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:46:00.455150Z",
     "start_time": "2019-10-19T16:46:00.215079Z"
    }
   },
   "outputs": [],
   "source": [
    "#annotating moving objects\n",
    "for (t, text, org) in all_texts:\n",
    "    cv2.putText(final_video[t], text, org, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (252, 240,3 ), 1)\n",
    "    #TODO: DESIGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T16:46:09.371792Z",
     "start_time": "2019-10-19T16:46:00.459500Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = os.path.basename(VID_PATH).split('.')[0]\n",
    "out = cv2.VideoWriter(filename+'_summary.avi',cv2.VideoWriter_fourcc(*'DIVX'), fps, (background.shape[1],background.shape[0]))\n",
    "\n",
    "for frame in final_video:\n",
    "    #cv2.imshow('Video summary',frame)\n",
    "    out.write(frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "#     tm.sleep(1/30) #TODO: FPS\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
